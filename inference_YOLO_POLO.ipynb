{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46d4c92",
   "metadata": {},
   "source": [
    "### Load dependencies \n",
    "We start by importing all necessary python packages, and the functionalities implemented in the utils folder of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e66fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.inference_YOLO import *\n",
    "from utils.model_eval import *\n",
    "from sahi.predict import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c82e2",
   "metadata": {},
   "source": [
    "### Insert paths, output directories, patch dimensions etc.\n",
    "Here we specify the inference parameters, including which model and test set to use, the dimensions of the patches, their overlap, etc. Some general info:\n",
    "- We use 640x640 patches in the paper. \n",
    "- The amount of overlap can be calculated from the values specified in Table 2. E.g.: $\\frac{128}{640} = 0.2$\n",
    "- The DoR and IoU values can be found in Table 12.\n",
    "- The radii can be found in the Size Avg. column of Table 1. They need to be passed as a dictionary where `key = class ID`, `value = radius`. The ID of a species is its position in the Species column of Table 1. E.g., for the JE-TL19 dataset, the `radii` dict would look as follows: `{0: 62, 1: 81, 2: 49}`\n",
    "- `classID2name` is a dictionary mapping class ids to their name. Again, for the JE-TL19 dataset: `classID2name = {0: \"Elephant\", 1: \"Giraffe\", 2: \"Zebra\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = \"\"   #TODO: Insert Path to image directory (as downloaded from Zenodo).\n",
    "output_dir = \"\"     #TODO: Insert path to directory you want your output stored in\n",
    "patch_dims = {\"width\": -1, \"height\": -1}  #TODO: Insert patch width and height; (640, 640) in the paper\n",
    "ovrlp = -1.0    #TODO: Define patch overlap as a fraction of the patch dimensions (e.g. 128 pixel overlap = 0.2 of 640x640 patches; cf. Table 2)\n",
    "dor_thresh = -1.0    #TODO: Define DoR threshold for NMS and computing evaluation metrics (cf. Table 12)\n",
    "iou_thresh = -1.0    #TODO: Define IoU threshold for NMS and computing evaluation metrics (cf. Table 12)\n",
    "mdl_path = \"\"     #TODO: Insert path to the model .pt file\n",
    "radii = {0: None, 1: None, 2: None}     #TODO: Insert radius for each species in the dataset; cf. Table 1.\n",
    "classID2name = {0: \"\", 1: \"\", 2: \"\"}    #TODO: Insert class ids and names as listed in Table 1.\n",
    "img_format = \"\"     #TODO: Specify the image format (suffix). E.g.: \"JPG\"/\"jpg\" (case sensitive)\n",
    "device = \"\"     #TODO: Insert device to be used for inference. \"cuda\" if you have access to a GPU, \"cpu\" otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d35c8",
   "metadata": {},
   "source": [
    "### Set some more paths (no input required)\n",
    "Here the path to the file containing the test set annotations, and to the tiling folder are set. The annotations file is needed to compute evaluation metrics and counting errors after inference, and the tiling folder is where the patches extracted from each image are going to be stored. We also set the random seed for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f94151",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = f\"{imgs_dir}/test_annotations.json\"\n",
    "tiling_dir = f\"{imgs_dir}/tiles\"\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e35b19",
   "metadata": {},
   "source": [
    "### Define Task\n",
    "Here we specify what model we will be using. Set the `task` variable to `\"locate\"` if you are working with a POLO model, use `\"detect\"` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"locate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbc734",
   "metadata": {},
   "source": [
    "### Run tiled inference (no input required)\n",
    "This is where we run the actual inference For bounding box models, we use the `SAHI` library, for POLO we use the methods implemented in `utils/inference_POLO.py`. `coco_file_path` will point to a json file required by `SAHI` to run tiled inference for bounding box models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"locate\":\n",
    "    run_tiled_inference_POLO(model=mdl_path, \n",
    "                             class_ids=list(radii.keys()),\n",
    "                             imgs_dir=imgs_dir, \n",
    "                             img_files_ext=img_format,\n",
    "                             patch_dims=patch_dims, \n",
    "                             patch_overlap=ovrlp, \n",
    "                             output_dir=output_dir,\n",
    "                             dor_thresh=dor_thresh,\n",
    "                             radii=radii,\n",
    "                             ann_file=ann_file,\n",
    "                             ann_format=\"PT_DEFAULT\")\n",
    "else:\n",
    "    coco_file_path = [p for p in Path(imgs_dir).glob(\"*.json\") if \"coco\" in p][0]\n",
    "    predict(\n",
    "        model_type=\"yolov8\",\n",
    "        model_path=mdl_path,\n",
    "        model_device=device, \n",
    "        source=imgs_dir,\n",
    "        slice_height=patch_dims[\"height\"],\n",
    "        slice_width=patch_dims[\"width\"],\n",
    "        overlap_height_ratio=ovrlp,\n",
    "        overlap_width_ratio=ovrlp,\n",
    "        postprocess_match_threshold=iou_thresh,\n",
    "        dataset_json_path=coco_file_path,\n",
    "        project=output_dir, \n",
    "        name=\"output_SAHI\",\n",
    "        novisual=True, \n",
    "        verbose=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757e7cd",
   "metadata": {},
   "source": [
    "### Compute Evaluation metrics\n",
    "This cell evaluated the ouputs of the previous cell. It will generate a number of files:\n",
    "- `count_diffs_img_lvl.xlsx`: Excel sheet containing the difference between predicted and ground truth count for each image.\n",
    "- `counts_gt_pred_*.png`: Plot of predicted vs. forund truth count for class `*`.\n",
    "- `counts_total.json`: Predicted counts summed over all images.\n",
    "- `em.json`: Evaluation metrics.\n",
    "- `errors_img_lvl.json`: Counting metrics.\n",
    "- `F1_curve.png`: F1 score plotted against the confidence threshold.\n",
    "- `P_curve.png`: Precision plotted against the confidence threshold.\n",
    "- `R_curve.png`: Recall plotted against the confidence threshold.\n",
    "\n",
    "Before running the cell, please set the `is_pseudo` variable to `True` if you are using a `YOLOv8` model trained on pseudo boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"detect\":\n",
    "    is_pseudo = None    #TODO: Set to True if you are using a YOLOv8 model trained on pseudo boxes\n",
    "\n",
    "    box_dims = {cid: {\"width\": radii[cid], \"height\": radii[cid]} for cid in radii.keys()} if is_pseudo else None\n",
    "    read_output_SAHI(out_json_SAHI=f\"{output_dir}/output_SAHI/result.json\", dataset_json_SAHI=coco_file_path, class_ids=list(classID2name.keys()), \n",
    "                         iou_thresh=iou_thresh, box_dims=box_dims, ann_file=ann_file, ann_format=\"BX_WH\", output_dir=output_dir)\n",
    "\n",
    "compute_errors_img_lvl(gt_counts_dir=f\"{imgs_dir}/image_counts\", pred_counts_dir=f\"{output_dir}/detections\", class_ids=list(classID2name.keys()), \n",
    "                           output_dir=output_dir)\n",
    "compute_em_img_lvl(preds_dir=f\"{output_dir}/detections\", class_id2name=classID2name, task=task, output_dir=output_dir)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P0_YOLOcate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
