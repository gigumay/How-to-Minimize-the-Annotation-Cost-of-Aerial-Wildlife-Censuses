{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bb599c",
   "metadata": {},
   "source": [
    "### Load dependencies \n",
    "We start by importing all necessary python packages, and the functionalities implemented in the utils folder of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20162ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.HN import *\n",
    "from utils.model_eval import *\n",
    "from utils.data_params import *\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686e856",
   "metadata": {},
   "source": [
    "### Insert dataset name, output directories, etc. (**TODO**)\n",
    "Here we specify the dataset we want to test, and set the some paths. For the dataset, please use the abbreviations given in the paper. E.g., `data_set = BK-L23`. This will load the corresponding DoR-threshold, radii, etc. in the next cell (values can also be found in the paper). Please set the following variables:\n",
    "- `data_set`: Name (abbreviation of the dataset).\n",
    "- `imgs_dir`: Path to the directory containing the test images of the dataset.\n",
    "- `model_weights`: Path to the trained model file (.pth).\n",
    "- `output_dir`: Path to the directory ourtputs can be stored in (must exist, is NOT going to be created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf808c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = \"\"\n",
    "imgs_dir = \"\" \n",
    "model_weights = \"\"\n",
    "output_dir = \"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774f9b2",
   "metadata": {},
   "source": [
    "For this next cell, no input is required - just run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classID2name =  parameters[data_set][\"classID2name_HN\"]\n",
    "dor_thresh = parameters[data_set][\"dor_thresh\"]\n",
    "radii = parameters[data_set][\"radii\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ef596",
   "metadata": {},
   "source": [
    "### Run inference (no input required)\n",
    "This cell will run HerdNet on the images from the “imgs_dir” entered above and will automatically create a folder inside it (HerdNet_results) in which the .csv file containing the detections will be saved.\n",
    "- `dets_file`: This is the path to the .csv file containing the HerdNet predictions. One row represents one detection and is expected to have the following columns:\n",
    "    - `images`: Contains the file names of the images.\n",
    "    - `x`: Contains the x-coordinate of the detection.\n",
    "    - `y`: Contains the y-coordinate of the detection.\n",
    "    - `scores`: Contains the confidence score of the prediction.\n",
    "    - `species`: Contains the name of the detected species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "#%run -m utils.inference_herdnet {imgs_dir} {model_weights} --size 640 --over 128\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "dets_file = next(Path(imgs_dir).rglob(\"*_HerdNet_detections.csv\"), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eee3e2",
   "metadata": {},
   "source": [
    "### Compute Evaluation metrics (no input required)\n",
    "This cell evaluated the ouputs of the previous cell. It will generate a number of files:\n",
    "- `count_diffs_img_lvl.xlsx`: Excel sheet containing the difference between predicted and ground truth count for each image.\n",
    "- `counts_gt_pred_*.png`: Plot of predicted vs. forund truth count for class `*`.\n",
    "- `counts_total.json`: Predicted counts summed over all images.\n",
    "- `em.json`: Evaluation metrics.\n",
    "- `errors_img_lvl.json`: Counting metrics.\n",
    "- `F1_curve.png`: F1 score plotted against the confidence threshold.\n",
    "- `P_curve.png`: Precision plotted against the confidence threshold.\n",
    "- `R_curve.png`: Recall plotted against the confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name2id =  {name: cid for cid,name in classID2name.items()}\n",
    "\n",
    "read_detections_HN(dets_file=dets_file, cls_name2id=class_name2id, imgs_dir=imgs_dir, dor_thresh=dor_thresh, radii=radii, class_ids=list(radii.keys()), output_dir=output_dir,\n",
    "                   ann_file=f\"{imgs_dir}/test_annotations.json\", ann_format=parameters[data_set][\"ann_format\"])\n",
    "compute_errors_img_lvl(gt_counts_dir=f\"{imgs_dir}/image_counts\", pred_counts_dir=f\"{output_dir}/detections\", class_ids=list(classID2name.keys()), \n",
    "                           output_dir=output_dir)\n",
    "compute_em_img_lvl(preds_dir=f\"{output_dir}/detections\", class_id2name=classID2name, task=\"locate\", output_dir=output_dir)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P0_YOLOcate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
